{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fad1ac",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Encodage et séparation des jeux de données\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Classifieur bayésien\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Arbre\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Précision du modèle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40c398",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_odr_filename = os.path.join(\".\", \"OT_ODR.csv.bz2\")\n",
    "ot_odr_df = pd.read_csv(ot_odr_filename,\n",
    "                        compression=\"bz2\",\n",
    "                        sep=\";\")\n",
    "\n",
    "equipements_filename = os.path.join(\".\", 'EQUIPEMENTS.csv')\n",
    "equipements_df = pd.read_csv(equipements_filename,\n",
    "                             sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37e498",
   "metadata": {},
   "source": [
    "# Nettoyage et traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure entre les deux jeus de données\n",
    "data = pd.merge(ot_odr_df, equipements_df, on='EQU_ID')\n",
    "\n",
    "# Définir les intervalles de 50 000 km pour la colonne kilométrage\n",
    "bins = range(0, int(data[\"KILOMETRAGE\"].max()) + 50000, 50000)\n",
    "labels = [f'{i}-{i+49999}' for i in bins[:-1]]\n",
    "\n",
    "# Créer une nouvelle colonne avec les classes de 50 000 km\n",
    "data['KILOMETRAGE_CLASSE'] = pd.cut(data[\"KILOMETRAGE\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# dumie de la variable sig_contexte\n",
    "dummies = data['SIG_CONTEXTE'].str.get_dummies(sep='/')\n",
    "data_origine = pd.concat([data, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942c6ac",
   "metadata": {},
   "source": [
    "# Prédiction SYSTEM_N1, SYSTEM_N2 et SYSTEM_N3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411455a0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Classifieur bayésien naïf</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b47b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(data, target_variable):\n",
    "    # Liste des colonnes à supprimer\n",
    "    columns_to_drop = [\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"ODR_LIBELLE\", \"ODR_ID\", \"OT_ID\", \n",
    "                       \"EQU_ID\", \"KILOMETRAGE\", \"DATE_OT\"]\n",
    "    columns_to_drop += [col for col in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"] if col != target_variable]\n",
    "\n",
    "    # Préparation des données\n",
    "    data_target = data.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "    X = data_target.drop([target_variable], axis=1)\n",
    "    y = data_target.filter([target_variable])\n",
    "    \n",
    "    # Encodage des variables utiles\n",
    "    le = LabelEncoder()\n",
    "    for column in X.columns:\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    naive_bayes = GaussianNB()\n",
    "    naive_bayes.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = naive_bayes.predict(x_test)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'\\nModèle pour {target_variable}:')\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(matrice_confusion)\n",
    "    \n",
    "    return accuracy, matrice_confusion\n",
    "\n",
    "# Exécution du modèle pour SYSTEM_N1, SYSTEM_N2, et SYSTEM_N3\n",
    "for target in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"]:\n",
    "    accuracy, matrice_confusion = train_and_evaluate_model(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f7beb",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>MLP</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19ae8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(data, target_variable):\n",
    "    # Liste des colonnes à supprimer\n",
    "    columns_to_drop = [\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"ODR_LIBELLE\", \"ODR_ID\", \"OT_ID\", \n",
    "                       \"EQU_ID\", \"KILOMETRAGE\", \"DATE_OT\"]\n",
    "    columns_to_drop += [col for col in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"] if col != target_variable]\n",
    "\n",
    "    # Préparation des données\n",
    "    data_target = data.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "    X = data_target.drop([target_variable], axis=1)\n",
    "    y = data_target.filter([target_variable])\n",
    "    \n",
    "    # Encodage des variables utiles\n",
    "    le = LabelEncoder()\n",
    "    for column in X.columns:\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\n",
    "\n",
    "    # MLP avec 1 couche cachée et 10 neurones, fonction d'activation RELU\n",
    "    clf = MLPClassifier(random_state=1,hidden_layer_sizes=(20,), activation='relu',max_iter=20).fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'\\nModèle pour {target_variable}:')\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(matrice_confusion)\n",
    "    \n",
    "    return accuracy, matrice_confusion\n",
    "\n",
    "# Exécution du modèle pour SYSTEM_N1, SYSTEM_N2, et SYSTEM_N3\n",
    "for target in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"]:\n",
    "    accuracy, matrice_confusion = train_and_evaluate_model(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79ff45",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Arbre de décision</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_tree(data, target_variable, A_pred):\n",
    "    # Liste des colonnes à supprimer\n",
    "    columns_to_drop = [\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"ODR_ID\", \"OT_ID\", \n",
    "                       \"EQU_ID\", \"KILOMETRAGE\", \"DATE_OT\"]\n",
    "    columns_to_drop += [col for col in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\",\"ODR_LIBELLE\"] if col != target_variable]\n",
    "\n",
    "    # Préparation des données\n",
    "    data_target = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "    X = data_target.drop([target_variable], axis=1)\n",
    "    y = data_target[target_variable]\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\n",
    "\n",
    "    # Encodage des variables utiles sur l'ensemble d'entraînement\n",
    "    label_encoders = {}\n",
    "    for column in x_train.columns:\n",
    "        le = LabelEncoder()\n",
    "        x_train[column] = le.fit_transform(x_train[column])\n",
    "        # Encoder les valeurs de x_test qui sont aussi présentes dans x_train\n",
    "        x_test[column] = x_test[column].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "        le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "        x_test[column] = le.transform(x_test[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    # Encodage de la variable cible sur l'ensemble d'entraînement\n",
    "    le_target = LabelEncoder()\n",
    "    y_train = le_target.fit_transform(y_train)\n",
    "    y_test = y_test.map(lambda s: '<unknown>' if s not in le_target.classes_ else s)\n",
    "    le_target.classes_ = np.append(le_target.classes_, '<unknown>')\n",
    "    y_test = le_target.transform(y_test)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    tree = DecisionTreeClassifier(max_depth=14)\n",
    "    tree.fit(x_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = tree.predict(x_test)\n",
    "    y_pred_proba = tree.predict_proba(x_test)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Prédiction avec de nouvelles données (A_pred)\n",
    "    A_pred = pd.DataFrame([A_pred], columns=x_train.columns)\n",
    "\n",
    "    for column in A_pred.columns:\n",
    "        if column in label_encoders:\n",
    "            le = label_encoders[column]\n",
    "            A_pred[column] = A_pred[column].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "            A_pred[column] = le.transform(A_pred[column])\n",
    "    \n",
    "    pred_proba = tree.predict_proba(A_pred)[0]  # Probabilités pour la première ligne de A_pred\n",
    "\n",
    "    # Obtenir la classe prédite avec la probabilité maximale\n",
    "    max_proba_index = np.argmax(pred_proba)\n",
    "    max_proba_class = le_target.inverse_transform([max_proba_index])[0]\n",
    "    max_proba_value = np.max(pred_proba)\n",
    "\n",
    "    return accuracy, max_proba_class, max_proba_value\n",
    "\n",
    "# Exécution du modèle pour SYSTEM_N1, SYSTEM_N2, SYSTEM_N3, et ODR_LIBELLE avec A_pred en entrée\n",
    "A_pred = [\"GLACE/BAIE\", \"DEBOITE\", \"L0482\", \"MD017\", \"C007\", \"MT014\", \"100000-149999\"]\n",
    "\n",
    "for target in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\", \"ODR_LIBELLE\"]:\n",
    "    accuracy, max_proba_class, max_proba_value = train_and_evaluate_model_tree(data, target, A_pred)\n",
    "    print(f'\\nModèle pour {target}:')\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    #print('Confusion Matrix :')\n",
    "    #print(matrice_confusion)\n",
    "    print(f'Classe prédite avec la probabilité la plus élevée : {max_proba_class}')\n",
    "    print(f'Probabilité : {max_proba_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e0932",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Random Forest</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_random_forest(data, target_variable):\n",
    "    # Liste des colonnes à supprimer\n",
    "    columns_to_drop = [\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"ODR_LIBELLE\", \"ODR_ID\", \"OT_ID\", \n",
    "                       \"EQU_ID\", \"KILOMETRAGE\", \"DATE_OT\"]\n",
    "    columns_to_drop += [col for col in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"] if col != target_variable]\n",
    "\n",
    "    # Préparation des données\n",
    "    data_target = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Encodage des variables utiles\n",
    "    le = LabelEncoder()\n",
    "    for column in data_target.columns:\n",
    "        data_target[column] = le.fit_transform(data_target[column])\n",
    "    \n",
    "    # Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "    X = data_target.drop([target_variable], axis=1)\n",
    "    y = data_target.filter([target_variable])\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'\\nModèle pour {target_variable}:')\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(matrice_confusion)\n",
    "\n",
    "    return accuracy, matrice_confusion\n",
    "\n",
    "# Exécution du modèle pour SYSTEM_N1, SYSTEM_N2, et SYSTEM_N3\n",
    "for target in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"]:\n",
    "    accuracy, matrice_confusion = train_and_evaluate_model_random_forest(data, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca67979",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>GridSearchCV</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f59768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(data, target_variable):\n",
    "    # Liste des colonnes à supprimer\n",
    "    columns_to_drop = [\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"ODR_LIBELLE\", \"ODR_ID\", \"OT_ID\", \n",
    "                       \"EQU_ID\", \"KILOMETRAGE\", \"DATE_OT\"] \n",
    "    columns_to_drop += [col for col in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"] if col != target_variable]\n",
    "\n",
    "    # Préparation des données\n",
    "    data_target = data.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "    X = data_target.drop([target_variable], axis=1)\n",
    "    y = data_target[target_variable]\n",
    "    \n",
    "    # Encodage des variables utiles\n",
    "    le = LabelEncoder()\n",
    "    for column in X.columns:\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)\n",
    "\n",
    "    # Définir le modèle et les paramètres pour GridSearchCV\n",
    "    model = GaussianNB()\n",
    "    param_grid = {\n",
    "        'var_smoothing': np.logspace(0, -9, num=100)  # Hyperparamètre à optimiser\n",
    "    }\n",
    "\n",
    "    # Utiliser GridSearchCV pour trouver les meilleurs hyperparamètres\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "    # Meilleur modèle et hyperparamètres\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f'\\nMeilleurs paramètres pour {target_variable}: {grid_search.best_params_}')\n",
    "\n",
    "    # Prédictions\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    y_pred_proba = best_model.predict_proba(x_test)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'\\nModèle pour {target_variable}:')\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(matrice_confusion)\n",
    "    \n",
    "    return accuracy, matrice_confusion\n",
    "\n",
    "# Exécution du modèle pour SYSTEM_N1, SYSTEM_N2, et SYSTEM_N3\n",
    "for target in [\"SYSTEM_N1\", \"SYSTEM_N2\", \"SYSTEM_N3\"]:\n",
    "    accuracy, matrice_confusion = train_and_evaluate_model(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdec17d",
   "metadata": {},
   "source": [
    "# Prédiction ODR_LIBELLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbc598",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: red;\">\n",
    "    <h1><em>Préparation</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2522b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_odr = data.drop([\"DUREE_TRAVAIL\", \"TYPE_TRAVAIL\", \"SIG_CONTEXTE\", \"SYSTEM_N3\", \"ODR_ID\", \"OT_ID\", \n",
    "                     \"EQU_ID\", \"SYSTEM_N1\", \"SYSTEM_N2\", \"KILOMETRAGE\", \"DATE_OT\"], axis=1)\n",
    "\n",
    "\n",
    "# Encodage des variables utiles\n",
    "le = LabelEncoder()\n",
    "for column in data_odr.columns:\n",
    "    data_odr[column] = le.fit_transform(data_odr[column])\n",
    "\n",
    "# Séparer les variables explicatives (X) et la variable à prédire (y)\n",
    "X = data_odr.drop([\"ODR_LIBELLE\"],axis=1)\n",
    "y = data_odr.filter([\"ODR_LIBELLE\"])\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "x_test, x_train, y_test, y_train = train_test_split(X, y, test_size=0.4, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3daaf7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Classifieur bayésien naïf</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = GaussianNB() \n",
    "naive_bayes.fit(x_train, y_train)\n",
    "y_pred = naive_bayes.predict(x_test)\n",
    "# Évaluation du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aab16b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>MLP</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP avec 1 couche cachée et 10 neurones, fonction d'activation RELU\n",
    "clf = MLPClassifier(random_state=1,hidden_layer_sizes=(20,), activation='relu',max_iter=20).fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c687d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP avec 1 couche cachée et 10 neurones, fonction d'activation Sigmoide\n",
    "clf = MLPClassifier(random_state=1,hidden_layer_sizes=(25,), activation='tanh',solver='sgd',\n",
    "                   learning_rate = 'adaptive', ,max_iter=20).fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(matrice_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30315879",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Arbre de décision</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eab3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,20):\n",
    "\n",
    "    # Construire et entraîner l'arbre de décision\n",
    "    tree1 = DecisionTreeClassifier(max_depth=i)\n",
    "    tree1.fit(x_train, y_train)\n",
    "\n",
    "    # Représentation de l'arbre (texte)\n",
    "    text_representation = tree.export_text(tree1, feature_names=list(x_train.columns))\n",
    "    #print(text_representation)\n",
    "\n",
    "    # Représentation de l'arbre (graphique)\n",
    "    #fig = plt.figure(figsize=(20, 10))\n",
    "    #tree_plot = tree.plot_tree(tree1, feature_names=X_train.columns, class_names=[str(cls) for cls in tree1.classes_], filled=True)\n",
    "    #plt.show()\n",
    "\n",
    "    # Prédiction et matrice de confusion\n",
    "    pred = tree1.predict(x_test)\n",
    "    conf_matrix = confusion_matrix(y_test, pred)\n",
    "    #print(\"Matrice de confusion:\\n\", conf_matrix)\n",
    "\n",
    "    # Calcul de l'accuracy\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(i,\"Précision (Accuracy):\", accuracy)\n",
    "\n",
    "    # Génération du rapport de classification\n",
    "    class_report = classification_report(y_test, pred)\n",
    "    #print(\"Rapport de classification:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f4fa1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1><em>Random Forest</em></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,20):\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=i)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    rf_model.fit(x_train, y_train)\n",
    "\n",
    "    # Prédiction sur l'ensemble de test\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "\n",
    "    # Évaluation de la précision du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(i, f\"Précision du modèle: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
